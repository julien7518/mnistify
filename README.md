# Mnistify

![App screenshot](public/og-image.png)

Live demo: https://mnistify.vercel.app

## Aper√ßu

Bienvenue sur Mnistify, un petit projet qui rend le machine learning amusant et accessible directement dans ton navigateur. Le but √©tait de cr√©er une exp√©rience interactive o√π tu peux jouer avec la reconnaissance de chiffres (dataset MNIST) en utilisant diff√©rents mod√®les de deep learning.

Tout se passe c√¥t√© client gr√¢ce √† WebGPU - donc pas de serveur co√ªteux, juste ton GPU qui travaille !

## Fonctionnalit√©s

üé® **Interface intuitive**

- Dessine tes propres chiffres
- Visualisation en temps r√©el des pr√©dictions

üìä **Visualisation des performances**

- Graphiques interactifs des pr√©dictions
- Comparaison des temps d'inf√©rence entre mod√®les

üîÑ **Mod√®les disponibles**

- MLP (Multi-Layer Perceptron) : rapide et l√©ger
- CNN (Convolutional Neural Network) : plus pr√©cis

## üöÄ Tech Stack

### üéØ Frontend

- **[React](https://react.dev/)** ‚Äì Biblioth√®que JavaScript.
- **[Next.js](https://nextjs.org/)** ‚Äì Framework React pour applications web.
- **[shadcn/ui](https://ui.shadcn.com/)** ‚Äì Biblioth√®que de composants UI.
- **[Tailwind CSS](https://tailwindcss.com/)** ‚Äì Framework CSS.
- **[Recharts](https://recharts.org/)** ‚Äì Biblioth√®que de visualisation de donn√©es bas√©e sur React.

### üß† Machine Learning

- **[Python 3.13.4](https://docs.python.org/3.13/)**
- **[TinyGrad](https://github.com/tinygrad/tinygrad)** ‚Äì Framework de deep learning.
- **[WebGPU](https://www.w3.org/TR/webgpu/)** ‚Äì API pour inf√©rence c√¥t√© client.
- **[SafeTensors](https://huggingface.co/docs/safetensors/index)** ‚Äì Format s√©curis√© pour le partage de mod√®les.

## R√©sum√© des mod√®les

### Meilleur MLP

| Type de couche | D√©tails                            |
| -------------- | ---------------------------------- |
| Entr√©e         | 784 neurones (image aplatie en 1D) |
| Couche dense 1 | 512 neurones avec activation SiLU  |
| Couche dense 2 | 512 neurones avec activation SiLU  |
| Sortie         | 10 neurones                        |

Pr√©cision finale (test): 94.49%

### Meilleur CNN

| Type de couche | D√©tails                                   |
| -------------- | ----------------------------------------- |
| Entr√©e         | Image 1 canal (28√ó28 pixels)              |
| Convolution 1  | 32 filtres de taille 5√ó5, activation SiLU |
| Convolution 2  | 32 filtres de taille 5√ó5, activation SiLU |
| Normalisation  | Normalisation par lots (32 canaux)        |
| Pooling        | Max-pooling (r√©duction de taille)         |
| Convolution 3  | 64 filtres de taille 3√ó3, activation SiLU |
| Convolution 4  | 64 filtres de taille 3√ó3, activation SiLU |
| Normalisation  | Normalisation par lots (64 canaux)        |
| Pooling        | Max-pooling (r√©duction de taille)         |
| Aplatissement  | Conversion en vecteur 1D                  |
| Couche dense   | 576 neurones vers 10 neurones             |

Pr√©cision finale (test): 98.22%

## Installation & ex√©cution locale

Pr√©-requis

- Node.js (recommand√© >= 18)
- Python 3.9+ (si vous voulez r√©-entra√Æner les mod√®les)
- Un environnement WebGPU compatible (navigateur r√©cent Chrome/Edge/Firefox Nightly avec drapeau WebGPU si n√©cessaire)

Frontend

```bash
# √† la racine du projet
npm install
npm run dev
```

Ouvrez http://localhost:3000 pour voir l'application.

Entra√Ænements des mod√®les

```bash
cd python
python -m pip install -r requirements.txt
python model_training/mlp.py
python model_training/cnn.py
```

## Journal d'hyperparam√®tres

Voir [`HYPERPARAMETERS.md`](/HYPERPARAMETERS.md).

## R√©trospective de projet

Ajoutez ici 3-6 phrases sur les d√©fis techniques rencontr√©s et les apprentissages (ex : limitations de tinygrad, adaptation des mod√®les pour WebGPU, compromis quant √† la taille du mod√®le vs latence, etc.).
